{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c514c1-2892-44c5-8ec6-b18159786a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06c71f7c-ea95-4cd5-847b-94bdbbdc0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "DATA_FOLDER = r'./data/TASKDATA'\n",
    "INTERIM_FOLDER  = r'./data/taskdata_out2'\n",
    "ENRICHED_FOLDER = r'./data/ENRICHED'\n",
    "OUT_ESPG = \"EPSG:25832\"\n",
    "# Safety Buffer: Add ~1km (0.01 deg) around the field to catch headland turns\n",
    "GEO_BUFFER = 0.01 \n",
    "BBOX_DEFAULT = (54.0, 58.0, 8.0, 16.0) # Denmark\n",
    "if not os.path.exists(INTERIM_FOLDER):\n",
    "    os.makedirs(INTERIM_FOLDER)\n",
    "if not os.path.exists(ENRICHED_FOLDER):\n",
    "    os.makedirs(ENRICHED_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d5e545-0f87-48a8-8ab2-75499f899052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STAGE 1: METADATA & DDI MAPPING ---\n",
      "Scanning ./data/TASKDATA for TASKDATA.XML...\n",
      "Index created. Found 142 tasks.\n",
      "\n",
      "--- STAGE 2: DYNAMIC BINARY EXTRACTION ---\n",
      "./data/TASKDATA/TLG00001.bin\n",
      "./data/TASKDATA/TLG00002.binsensors)...\n",
      "./data/TASKDATA/TLG00003.binsensors)...\n",
      "./data/TASKDATA/TLG00004.binsensors)...\n",
      "./data/TASKDATA/TLG00005.binsensors)...\n",
      "./data/TASKDATA/TLG00006.binsensors)...\n",
      "./data/TASKDATA/TLG00007.binsensors)...\n",
      "./data/TASKDATA/TLG00008.binsensors)...\n",
      "./data/TASKDATA/TLG00009.binsensors)...\n",
      "./data/TASKDATA/TLG00010.binsensors)...\n",
      "./data/TASKDATA/TLG00011.binsensors)...\n",
      "./data/TASKDATA/TLG00012.binsensors)...\n",
      "./data/TASKDATA/TLG00013.binsensors)...\n",
      "./data/TASKDATA/TLG00014.binsensors)...\n",
      "./data/TASKDATA/TLG00015.binsensors)...\n",
      "./data/TASKDATA/TLG00016.binsensors)...\n",
      "./data/TASKDATA/TLG00017.binsensors)...\n",
      "./data/TASKDATA/TLG00018.binsensors)...\n",
      "./data/TASKDATA/TLG00019.binsensors)...\n",
      "./data/TASKDATA/TLG00020.binsensors)...\n",
      "./data/TASKDATA/TLG00021.binsensors)...\n",
      "./data/TASKDATA/TLG00022.binsensors)...\n",
      "./data/TASKDATA/TLG00023.binsensors)...\n",
      "./data/TASKDATA/TLG00024.binsensors)...\n",
      "./data/TASKDATA/TLG00025.binsensors)...\n",
      "./data/TASKDATA/TLG00026.binsensors)...\n",
      "./data/TASKDATA/TLG00027.binsensors)...\n",
      "./data/TASKDATA/TLG00028.binsensors)...\n",
      "./data/TASKDATA/TLG00029.binsensors)...\n",
      "./data/TASKDATA/TLG00030.binsensors)...\n",
      "./data/TASKDATA/TLG00031.binsensors)...\n",
      "./data/TASKDATA/TLG00032.binsensors)...\n",
      "./data/TASKDATA/TLG00033.binsensors)...\n",
      "./data/TASKDATA/TLG00034.binsensors)...\n",
      "./data/TASKDATA/TLG00035.binsensors)...\n",
      "./data/TASKDATA/TLG00036.binsensors)...\n",
      "./data/TASKDATA/TLG00037.binsensors)...\n",
      "./data/TASKDATA/TLG00038.binsensors)...\n",
      "./data/TASKDATA/TLG00039.binsensors)...\n",
      "./data/TASKDATA/TLG00040.binsensors)...\n",
      "./data/TASKDATA/TLG00041.binsensors)...\n",
      "./data/TASKDATA/TLG00042.binsensors)...\n",
      "./data/TASKDATA/TLG00043.binsensors)...\n",
      "./data/TASKDATA/TLG00044.binsensors)...\n",
      "./data/TASKDATA/TLG00045.binsensors)...\n",
      "./data/TASKDATA/TLG00046.binsensors)...\n",
      "./data/TASKDATA/TLG00047.binsensors)...\n",
      "./data/TASKDATA/TLG00048.binsensors)...\n",
      "./data/TASKDATA/TLG00049.binsensors)...\n",
      "./data/TASKDATA/TLG00050.binsensors)...\n",
      "./data/TASKDATA/TLG00051.binsensors)...\n",
      "./data/TASKDATA/TLG00052.binsensors)...\n",
      "./data/TASKDATA/TLG00053.binsensors)...\n",
      "./data/TASKDATA/TLG00054.binsensors)...\n",
      "./data/TASKDATA/TLG00055.binsensors)...\n",
      "./data/TASKDATA/TLG00056.binsensors)...\n",
      "./data/TASKDATA/TLG00057.binsensors)...\n",
      "./data/TASKDATA/TLG00058.binsensors)...\n",
      "./data/TASKDATA/TLG00059.binsensors)...\n",
      "./data/TASKDATA/TLG00060.binsensors)...\n",
      "./data/TASKDATA/TLG00061.binsensors)...\n",
      "./data/TASKDATA/TLG00062.binsensors)...\n",
      "./data/TASKDATA/TLG00063.binsensors)...\n",
      "./data/TASKDATA/TLG00064.binsensors)...\n",
      "./data/TASKDATA/TLG00065.binsensors)...\n",
      "./data/TASKDATA/TLG00066.binsensors)...\n",
      "./data/TASKDATA/TLG00067.binsensors)...\n",
      "./data/TASKDATA/TLG00068.binsensors)...\n",
      "./data/TASKDATA/TLG00069.binsensors)...\n",
      "./data/TASKDATA/TLG00070.binsensors)...\n",
      "./data/TASKDATA/TLG00071.binsensors)...\n",
      "./data/TASKDATA/TLG00072.binsensors)...\n",
      "./data/TASKDATA/TLG00073.binsensors)...\n",
      "./data/TASKDATA/TLG00074.binsensors)...\n",
      "./data/TASKDATA/TLG00075.binsensors)...\n",
      "./data/TASKDATA/TLG00076.binsensors)...\n",
      "./data/TASKDATA/TLG00077.binsensors)...\n",
      "./data/TASKDATA/TLG00078.binsensors)...\n",
      "./data/TASKDATA/TLG00079.binsensors)...\n",
      "./data/TASKDATA/TLG00080.binsensors)...\n",
      "./data/TASKDATA/TLG00081.binsensors)...\n",
      "./data/TASKDATA/TLG00082.binsensors)...\n",
      "./data/TASKDATA/TLG00083.binsensors)...\n",
      "./data/TASKDATA/TLG00084.binsensors)...\n",
      "./data/TASKDATA/TLG00085.binsensors)...\n",
      "./data/TASKDATA/TLG00086.binsensors)...\n",
      "./data/TASKDATA/TLG00087.binsensors)...\n",
      "./data/TASKDATA/TLG00088.binsensors)...\n",
      "./data/TASKDATA/TLG00089.binsensors)...\n",
      "./data/TASKDATA/TLG00090.binsensors)...\n",
      "./data/TASKDATA/TLG00091.binsensors)...\n",
      "./data/TASKDATA/TLG00092.binsensors)...\n",
      "./data/TASKDATA/TLG00093.binsensors)...\n",
      "./data/TASKDATA/TLG00094.binsensors)...\n",
      "./data/TASKDATA/TLG00095.binsensors)...\n",
      "./data/TASKDATA/TLG00096.binsensors)...\n",
      "./data/TASKDATA/TLG00097.binsensors)...\n",
      "./data/TASKDATA/TLG00098.binsensors)...\n",
      "./data/TASKDATA/TLG00099.binsensors)...\n",
      "./data/TASKDATA/TLG00100.binsensors)...\n",
      "./data/TASKDATA/TLG00101.binsensors)...\n",
      "./data/TASKDATA/TLG00102.binsensors)...\n",
      "./data/TASKDATA/TLG00103.binsensors)...\n",
      "./data/TASKDATA/TLG00104.binsensors)...\n",
      "./data/TASKDATA/TLG00105.binsensors)...\n",
      "./data/TASKDATA/TLG00106.binsensors)...\n",
      "./data/TASKDATA/TLG00107.binsensors)...\n",
      "./data/TASKDATA/TLG00108.binsensors)...\n",
      "./data/TASKDATA/TLG00109.binsensors)...\n",
      "./data/TASKDATA/TLG00110.binsensors)...\n",
      "./data/TASKDATA/TLG00111.binsensors)...\n",
      "./data/TASKDATA/TLG00112.binsensors)...\n",
      "./data/TASKDATA/TLG00113.binsensors)...\n",
      "./data/TASKDATA/TLG00114.binsensors)...\n",
      "./data/TASKDATA/TLG00115.binsensors)...\n",
      "./data/TASKDATA/TLG00116.binsensors)...\n",
      "./data/TASKDATA/TLG00117.binsensors)...\n",
      "./data/TASKDATA/TLG00118.binsensors)...\n",
      "./data/TASKDATA/TLG00119.binsensors)...\n",
      "./data/TASKDATA/TLG00120.binsensors)...\n",
      "./data/TASKDATA/TLG00121.binsensors)...\n",
      "./data/TASKDATA/TLG00122.binsensors)...\n",
      "./data/TASKDATA/TLG00123.binsensors)...\n",
      "./data/TASKDATA/TLG00124.binsensors)...\n",
      "./data/TASKDATA/TLG00125.binsensors)...\n",
      "./data/TASKDATA/TLG00126.binsensors)...\n",
      "./data/TASKDATA/TLG00127.binsensors)...\n",
      "./data/TASKDATA/TLG00128.binsensors)...\n",
      "./data/TASKDATA/TLG00129.binsensors)...\n",
      "./data/TASKDATA/TLG00130.binsensors)...\n",
      "./data/TASKDATA/TLG00131.binsensors)...\n",
      "./data/TASKDATA/TLG00132.binsensors)...\n",
      "./data/TASKDATA/TLG00133.binsensors)...\n",
      "./data/TASKDATA/TLG00134.binsensors)...\n",
      "./data/TASKDATA/TLG00135.binsensors)...\n",
      "./data/TASKDATA/TLG00136.binsensors)...\n",
      "./data/TASKDATA/TLG00137.binsensors)...\n",
      "./data/TASKDATA/TLG00138.binsensors)...\n",
      "./data/TASKDATA/TLG00139.binsensors)...\n",
      "./data/TASKDATA/TLG00140.binsensors)...\n",
      "./data/TASKDATA/TLG00141.binsensors)...\n",
      "./data/TASKDATA/TLG00142.binsensors)...\n",
      "Processing TLG00142.bin (14 sensors)...\n",
      "Done. Extracted 142 files.\n",
      "Check ./data/taskdata_out2/TLG00008.csv - It should now have 17+ columns including Proprietary data.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. METADATA PARSER (Corrected with Sidecar XML Check)\n",
    "# ==========================================\n",
    "def parse_isobus_taskdata(data_folder):\n",
    "    print(f\"Scanning {data_folder} for TASKDATA.XML...\")\n",
    "    taskdata_path = os.path.join(data_folder, 'TASKDATA.XML')\n",
    "    \n",
    "    if not os.path.exists(taskdata_path):\n",
    "        print(\"Error: TASKDATA.XML not found.\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        tree = ET.parse(taskdata_path)\n",
    "        root = tree.getroot()\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # 1. Parse Products & Fields\n",
    "    products = {p.attrib.get('A'): p.attrib.get('B') for p in root.findall(\".//PDT\")}\n",
    "    field_names = {f.attrib.get('A'): f.attrib.get('C') for f in root.findall(\".//PFD\")}\n",
    "    \n",
    "    # 2. Get Field Bounds\n",
    "    field_bounds = {}\n",
    "    for pfd in root.findall(\".//PFD\"):\n",
    "        lats, lons = [], []\n",
    "        for pnt in pfd.findall(\".//PNT\"):\n",
    "            try:\n",
    "                lats.append(float(pnt.attrib.get('C')))\n",
    "                lons.append(float(pnt.attrib.get('D')))\n",
    "            except: pass\n",
    "        if lats:\n",
    "            field_bounds[pfd.attrib.get('A')] = (min(lats)-GEO_BUFFER, max(lats)+GEO_BUFFER, \n",
    "                                                 min(lons)-GEO_BUFFER, max(lons)+GEO_BUFFER)\n",
    "\n",
    "    # 3. Build Task Index\n",
    "    tasks_list = []\n",
    "    \n",
    "    for tsk in root.findall(\".//TSK\"):\n",
    "        tlg = tsk.find(\"TLG\")\n",
    "        if tlg is None: continue\n",
    "        \n",
    "        log_filename = tlg.attrib.get('A') + '.bin'\n",
    "        \n",
    "        # --- NEW: Look for Sidecar XML for DDIs ---\n",
    "        ddi_list = []\n",
    "        \n",
    "        # Strategy A: Check TLGxxxxx.xml in the same folder\n",
    "        sidecar_xml = log_filename.replace('.bin', '.xml')\n",
    "        sidecar_path = os.path.join(data_folder, sidecar_xml)\n",
    "        \n",
    "        if os.path.exists(sidecar_path):\n",
    "            try:\n",
    "                side_tree = ET.parse(sidecar_path)\n",
    "                # Look for DLV tags anywhere in the sidecar file\n",
    "                for dlv in side_tree.findall(\".//DLV\"):\n",
    "                    ddi_list.append(dlv.attrib.get('A'))\n",
    "            except: pass\n",
    "            \n",
    "        # Strategy B: Check TASKDATA.XML if Strategy A failed\n",
    "        if not ddi_list:\n",
    "            tim = tsk.find(\"TIM\")\n",
    "            if tim is not None:\n",
    "                for dlv in tim.findall(\"DLV\"):\n",
    "                    ddi_list.append(dlv.attrib.get('A'))\n",
    "\n",
    "        # Strategy C: Fallback to Standard 4 (Prevent 0-byte payload crash)\n",
    "        if not ddi_list:\n",
    "            ddi_list = ['0054', '0095', '018D', '0063']\n",
    "\n",
    "        # Metadata\n",
    "        crop = \"Unknown\"\n",
    "        pan = tsk.find(\"PAN\")\n",
    "        if pan is not None: # Fixed Deprecation Warning\n",
    "            crop = products.get(pan.attrib.get('A'), crop)\n",
    "        \n",
    "        field_id = tsk.attrib.get('E')\n",
    "        field_name = field_names.get(field_id, f\"Unknown_{field_id}\")\n",
    "        bounds = field_bounds.get(field_id, (54.0, 58.0, 8.0, 16.0))\n",
    "        \n",
    "        try:\n",
    "            # Safe date parsing\n",
    "            tim_node = tsk.find(\"TIM\")\n",
    "            start_str = tim_node.attrib.get('A') if tim_node is not None else \"\"\n",
    "            dt = datetime.fromisoformat(start_str.replace('Z',''))\n",
    "            year = dt.year\n",
    "        except: year = 2024\n",
    "        \n",
    "        tasks_list.append({\n",
    "            'LogFilename': log_filename,\n",
    "            'Year': year,\n",
    "            'Crop': crop,\n",
    "            'FieldName': field_name,\n",
    "            'DDI_List': json.dumps(ddi_list),\n",
    "            'Bounds': json.dumps(bounds)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(tasks_list)\n",
    "\n",
    "# ==========================================\n",
    "# 2. DYNAMIC BINARY CONVERTER\n",
    "# ==========================================\n",
    "def convert_bin_to_csv(bin_path, out_csv_path, ddi_list, bounds):\n",
    "    if not os.path.exists(bin_path): return False\n",
    "    \n",
    "    min_lat, max_lat, min_lon, max_lon = bounds\n",
    "    \n",
    "    # Calculate Payload Size dynamically\n",
    "    # 14 sensors = 56 bytes\n",
    "    num_sensors = len(ddi_list)\n",
    "    payload_size = num_sensors * 4\n",
    "    \n",
    "    with open(bin_path, 'rb') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    total_len = len(content)\n",
    "    cursor = 0\n",
    "    valid_rows = []\n",
    "    last_valid_end = 0\n",
    "    \n",
    "    # Extended Map\n",
    "    DDI_MAP = {\n",
    "        '0054': 'Yield_Mass',   '0095': 'Yield_Vol', \n",
    "        '018D': 'Speed',        '0063': 'Moisture',\n",
    "        '0053': 'Dry_Mass',     '008D': 'Engine_Load',\n",
    "        '013A': 'Fuel_Rate',    'E122': 'Header_Status',\n",
    "        '0055': 'Crop_Temp_Or_Count'\n",
    "    }\n",
    "    # Generate column names: Use Name if known, else DDI_Code\n",
    "    col_names = [DDI_MAP.get(d, f\"DDI_{d}\") for d in ddi_list]\n",
    "    \n",
    "    while cursor < total_len - (12 + payload_size):\n",
    "        match_found = False\n",
    "        bytes_consumed = 0\n",
    "        \n",
    "        try:\n",
    "            # 1. Header\n",
    "            time_ms, lat_raw, lon_raw = struct.unpack('<Lii', content[cursor:cursor+12])\n",
    "            lat = lat_raw * 1e-7\n",
    "            lon = lon_raw * 1e-7\n",
    "            \n",
    "            # 2. Geo-Filter\n",
    "            if (min_lat < lat < max_lat) and (min_lon < lon < max_lon):\n",
    "                \n",
    "                # 3. Dynamic Payload\n",
    "                # Read exactly 'num_sensors' Unsigned Integers\n",
    "                values = struct.unpack(f'{num_sensors}I', content[cursor+12 : cursor+12+payload_size])\n",
    "                \n",
    "                match_found = True\n",
    "                bytes_consumed = 12 + payload_size\n",
    "                \n",
    "                row = {\n",
    "                    'Time_ms': time_ms,\n",
    "                    'Latitude': lat,\n",
    "                    'Longitude': lon,\n",
    "                    'Gap_Bytes': cursor - last_valid_end\n",
    "                }\n",
    "                \n",
    "                # Assign values to columns\n",
    "                for i, val in enumerate(values):\n",
    "                    row[col_names[i]] = val\n",
    "                    \n",
    "                valid_rows.append(row)\n",
    "                \n",
    "        except: pass\n",
    "            \n",
    "        if match_found:\n",
    "            last_valid_end = cursor + bytes_consumed\n",
    "            cursor += bytes_consumed\n",
    "        else:\n",
    "            cursor += 1\n",
    "            \n",
    "    if valid_rows:\n",
    "        pd.DataFrame(valid_rows).to_csv(out_csv_path, index=False)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION\n",
    "# ==========================================\n",
    "print(\"--- STAGE 1: METADATA & DDI MAPPING ---\")\n",
    "df_index = parse_isobus_taskdata(DATA_FOLDER)\n",
    "\n",
    "if df_index is not None:\n",
    "    df_index.to_csv(os.path.join(INTERIM_FOLDER, 'task_index.csv'), index=False)\n",
    "    print(f\"Index created. Found {len(df_index)} tasks.\")\n",
    "    \n",
    "    print(\"\\n--- STAGE 2: DYNAMIC BINARY EXTRACTION ---\")\n",
    "    count = 0\n",
    "    for idx, row in df_index.iterrows():\n",
    "        bin_file = os.path.join(DATA_FOLDER, row['LogFilename'])\n",
    "        out_file = os.path.join(INTERIM_FOLDER, row['LogFilename'].replace('.bin', '.csv'))\n",
    "        # Load the specific DDI list for this file\n",
    "        ddi_list = json.loads(row['DDI_List'])\n",
    "        bounds = json.loads(row['Bounds'])\n",
    "        \n",
    "        print(f\"Processing {row['LogFilename']} ({len(ddi_list)} sensors)...\", end='\\r')\n",
    "        if convert_bin_to_csv(bin_file, out_file, ddi_list, bounds):\n",
    "            count += 1\n",
    "            \n",
    "    print(f\"\\nDone. Extracted {count} files.\")\n",
    "    print(f\"Check {INTERIM_FOLDER}/TLG00008.csv - It should now have 17+ columns including Proprietary data.\")\n",
    "else:\n",
    "    print(\"Failed to parse metadata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd0a01-6861-4cc9-a95b-64355f4d6717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
