{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2065195",
   "metadata": {},
   "source": [
    "# Kriging Interpolation of Yield Data\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook performs **spatial interpolation (kriging)** on harvest yield data to:\n",
    "1. Load validated point data from GeoPackage (from 02_Spatial_Yield_Analysis)\n",
    "2. Apply manual exclusion filters for problematic data (e.g., harvester edge effects)\n",
    "3. Fit variogram models to understand spatial correlation\n",
    "4. Perform kriging interpolation with two strategies:\n",
    "   - **Combined model**: All years together (using normalized relative yield)\n",
    "   - **Separate models**: Individual kriging per year\n",
    "5. Compare results and create interpolated yield surfaces\n",
    "\n",
    "## Why Two Approaches?\n",
    "\n",
    "- **Combined (all years)**: Relative yield is already normalized to crop-year averages, so spatial patterns may be consistent across years. More data points = more robust variogram.\n",
    "- **Separate (per year)**: Each year may have unique weather/management effects that create different spatial structures.\n",
    "\n",
    "## Output\n",
    "\n",
    "- Variogram plots showing spatial correlation\n",
    "- Interpolated yield surfaces (rasters)\n",
    "- Cross-validation statistics (RMSE, MAE)\n",
    "- Comparison of both kriging strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a64f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries loaded successfully\n",
      "  PyKrige available: True\n",
      "  Rasterio available: True\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Import Required Libraries\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import logging\n",
    "\n",
    "# Spatial analysis\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Kriging libraries\n",
    "try:\n",
    "    import pykrige\n",
    "    from pykrige.ok import OrdinaryKriging\n",
    "    from pykrige.uk import UniversalKriging\n",
    "    HAS_PYKRIGE = True\n",
    "except ImportError:\n",
    "    HAS_PYKRIGE = False\n",
    "    print(\"‚ö† PyKrige not installed: pip install pykrige\")\n",
    "\n",
    "# Raster export\n",
    "try:\n",
    "    import rasterio\n",
    "    from rasterio.transform import from_bounds\n",
    "    HAS_RASTERIO = True\n",
    "except ImportError:\n",
    "    HAS_RASTERIO = False\n",
    "    print(\"‚ö† Rasterio not installed: pip install rasterio\")\n",
    "\n",
    "# Setup logging\n",
    "logger = logging.getLogger('03_Kriging_Interpolation')\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully\")\n",
    "print(f\"  PyKrige available: {HAS_PYKRIGE}\")\n",
    "print(f\"  Rasterio available: {HAS_RASTERIO}\")\n",
    "\n",
    "if not HAS_PYKRIGE:\n",
    "    print(\"\\n‚ùå PyKrige is required for this notebook. Install with: pip install pykrige\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b892c8",
   "metadata": {},
   "source": [
    "## Configuration & Data Paths\n",
    "\n",
    "Set paths to load the GeoPackage from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e0577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Project root: /Users/holmes/local_dev/agri_analysis\n",
      "Input GeoPackage: /Users/holmes/local_dev/agri_analysis/data/spatial_analysis/yield_points_utm.gpkg\n",
      "Output directory: /Users/holmes/local_dev/agri_analysis/data/kriging_results\n",
      "Grid resolution: 10m\n"
     ]
    }
   ],
   "source": [
    "# Configuration: Set paths\n",
    "\n",
    "# Project root\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "SPATIAL_DIR = DATA_DIR / 'spatial_analysis'\n",
    "\n",
    "# Input: GeoPackage from 02_Spatial_Yield_Analysis\n",
    "GEOPACKAGE_PATH = SPATIAL_DIR / 'yield_points_utm.gpkg'\n",
    "\n",
    "# Output directory for kriging results\n",
    "KRIGING_OUTPUT_DIR = DATA_DIR / 'kriging_results'\n",
    "KRIGING_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Kriging parameters\n",
    "GRID_RESOLUTION = 10  # meters (10m grid for interpolation)\n",
    "VARIOGRAM_MODELS = ['spherical', 'exponential', 'gaussian']  # Models to test\n",
    "N_LAGS = 15  # Number of lag bins for variogram\n",
    "\n",
    "logger.info(f\"Project root: {PROJECT_ROOT}\")\n",
    "logger.info(f\"Input GeoPackage: {GEOPACKAGE_PATH}\")\n",
    "logger.info(f\"Output directory: {KRIGING_OUTPUT_DIR}\")\n",
    "logger.info(f\"Grid resolution: {GRID_RESOLUTION}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a644aa2",
   "metadata": {},
   "source": [
    "## Section 2: Load Yield Data from GeoPackage\n",
    "\n",
    "Load the validated and normalized yield points with UTM coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32661d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/holmes/local_dev/agri_analysis/data/spatial_analysis/yield_points_utm.gpkg...\n",
      "Loaded 593,596 points\n",
      "CRS: EPSG:25832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADED DATA SUMMARY\n",
      "================================================================================\n",
      "Total points: 593,596\n",
      "CRS: EPSG:25832\n",
      "\n",
      "Crops: ['VB - V√•rbyg' 'RG - Rajgr√¶s' 'RA - Raps / rybs' 'HV - Hvede'\n",
      " 'VIB - Vinterbyg' 'KLL - Kl√∏ver / lucerne']\n",
      "Years: [np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "Fields: 28 unique fields\n",
      "\n",
      "Columns available:\n",
      "  - x_utm\n",
      "  - y_utm\n",
      "  - Crop\n",
      "  - Year\n",
      "  - Field\n",
      "  - CompositeTLGID\n",
      "  - yield_t_ha\n",
      "  - avg_yield_t_ha\n",
      "  - relative_yield\n",
      "  - latitude\n",
      "  - longitude\n",
      "  - time_stamp\n",
      "  - fugtighed\n",
      "\n",
      "Relative yield statistics:\n",
      "  Mean: 1.000\n",
      "  Std: 0.394\n",
      "  Range: [0.002, 39.513]\n",
      "\n",
      "Sample data:\n",
      "           x_utm         y_utm         Crop  Year  yield_t_ha  relative_yield\n",
      "0  684762.512894  6.165175e+06  VB - V√•rbyg  2022       5.586        0.808531\n",
      "1  684760.956886  6.165175e+06  VB - V√•rbyg  2022       5.586        0.808531\n",
      "2  684758.242243  6.165175e+06  VB - V√•rbyg  2022       6.462        0.935325\n",
      "3  684755.745038  6.165175e+06  VB - V√•rbyg  2022       2.678        0.387620\n",
      "4  684754.024144  6.165175e+06  VB - V√•rbyg  2022       0.816        0.118110\n"
     ]
    }
   ],
   "source": [
    "# Load GeoPackage data\n",
    "logger.info(f\"Loading data from {GEOPACKAGE_PATH}...\")\n",
    "\n",
    "if not GEOPACKAGE_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"GeoPackage not found: {GEOPACKAGE_PATH}\\n\"\n",
    "        \"Please run 02_Spatial_Yield_Analysis.ipynb first to generate the data.\"\n",
    "    )\n",
    "\n",
    "gdf = gpd.read_file(GEOPACKAGE_PATH)\n",
    "\n",
    "logger.info(f\"Loaded {len(gdf):,} points\")\n",
    "logger.info(f\"CRS: {gdf.crs}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADED DATA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total points: {len(gdf):,}\")\n",
    "print(f\"CRS: {gdf.crs}\")\n",
    "print(f\"\\nCrops: {gdf['Crop'].unique()}\")\n",
    "print(f\"Years: {sorted(gdf['Year'].unique())}\")\n",
    "print(f\"Fields: {gdf['Field'].nunique()} unique fields\")\n",
    "\n",
    "print(f\"\\nColumns available:\")\n",
    "for col in gdf.columns:\n",
    "    if col != 'geometry':\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nRelative yield statistics:\")\n",
    "print(f\"  Mean: {gdf['relative_yield'].mean():.3f}\")\n",
    "print(f\"  Std: {gdf['relative_yield'].std():.3f}\")\n",
    "print(f\"  Range: [{gdf['relative_yield'].min():.3f}, {gdf['relative_yield'].max():.3f}]\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample data:\")\n",
    "print(gdf[['x_utm', 'y_utm', 'Crop', 'Year', 'yield_t_ha', 'relative_yield']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36ab1e",
   "metadata": {},
   "source": [
    "## Section 3: Manual Exclusion of Problematic Data\n",
    "\n",
    "Add a filter to exclude problematic points (e.g., harvester edge effects, calibration errors).\n",
    "\n",
    "You can modify the exclusion criteria below based on visual inspection of the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8151f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Excluded 2499 extreme outliers (>3 std from mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXCLUSION SUMMARY\n",
      "================================================================================\n",
      "Original points: 593,596\n",
      "Excluded points: 2,499 (0.4%)\n",
      "Valid points for kriging: 591,097\n",
      "\n",
      "Valid points by Crop and Year:\n",
      "Crop                    Year\n",
      "HV - Hvede              2021    20500\n",
      "                        2022    36362\n",
      "                        2023    29868\n",
      "                        2024    39214\n",
      "                        2025    45156\n",
      "KLL - Kl√∏ver / lucerne  2022    11639\n",
      "RA - Raps / rybs        2021    13909\n",
      "                        2022     2224\n",
      "                        2023    15990\n",
      "                        2024    27048\n",
      "                        2025    10286\n",
      "RG - Rajgr√¶s            2021    17311\n",
      "                        2022     3472\n",
      "                        2023    50144\n",
      "                        2024    87572\n",
      "                        2025    43028\n",
      "VB - V√•rbyg             2021     8296\n",
      "                        2022    19326\n",
      "                        2023    11954\n",
      "                        2024    27222\n",
      "                        2025    32934\n",
      "VIB - Vinterbyg         2022    20100\n",
      "                        2023    17542\n",
      "dtype: int64\n",
      "\n",
      "üí° Tip: To manually exclude more points, modify the exclusion criteria above.\n",
      "   You can exclude by Field name, coordinate ranges, or other attributes.\n"
     ]
    }
   ],
   "source": [
    "# Manual exclusion filters\n",
    "# Modify these criteria based on data quality inspection\n",
    "\n",
    "# Initialize exclude flag (all points included by default)\n",
    "gdf['exclude'] = False\n",
    "\n",
    "# Example exclusion criteria:\n",
    "# 1. Extreme outliers (relative yield > 3 std from mean)\n",
    "mean_ry = gdf['relative_yield'].mean()\n",
    "std_ry = gdf['relative_yield'].std()\n",
    "outlier_threshold = 3\n",
    "outliers = (gdf['relative_yield'] < mean_ry - outlier_threshold * std_ry) | \\\n",
    "           (gdf['relative_yield'] > mean_ry + outlier_threshold * std_ry)\n",
    "gdf.loc[outliers, 'exclude'] = True\n",
    "\n",
    "logger.info(f\"Excluded {outliers.sum()} extreme outliers (>{outlier_threshold} std from mean)\")\n",
    "\n",
    "# 2. Manual geographic exclusion (example: exclude specific field or area)\n",
    "# Uncomment and modify as needed:\n",
    "# gdf.loc[gdf['Field'] == 'Problematic_Field_Name', 'exclude'] = True\n",
    "\n",
    "# 3. You can also exclude based on spatial patterns (e.g., field edges)\n",
    "# This would require defining boundaries - can be added later\n",
    "\n",
    "# Filter to valid points for kriging\n",
    "gdf_valid = gdf[~gdf['exclude']].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXCLUSION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Original points: {len(gdf):,}\")\n",
    "print(f\"Excluded points: {gdf['exclude'].sum():,} ({100*gdf['exclude'].sum()/len(gdf):.1f}%)\")\n",
    "print(f\"Valid points for kriging: {len(gdf_valid):,}\")\n",
    "\n",
    "print(f\"\\nValid points by Crop and Year:\")\n",
    "print(gdf_valid.groupby(['Crop', 'Year']).size())\n",
    "\n",
    "print(f\"\\nüí° Tip: To manually exclude more points, modify the exclusion criteria above.\")\n",
    "print(f\"   You can exclude by Field name, coordinate ranges, or other attributes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de755c15",
   "metadata": {},
   "source": [
    "## Section 4: Variogram Analysis\n",
    "\n",
    "Analyze spatial autocorrelation by computing and plotting experimental variograms.\n",
    "\n",
    "This helps us understand:\n",
    "- **Range**: Distance at which points become uncorrelated\n",
    "- **Sill**: Maximum variance between points\n",
    "- **Nugget**: Variance at zero distance (measurement error + micro-scale variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7c8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing variogram for 591,097 points...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VARIOGRAM ANALYSIS: ALL YEARS COMBINED\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Variogram analysis: Combined (all years)\n",
    "# Note: Variogram computation can be memory-intensive for large datasets\n",
    "# We subsample if needed to avoid kernel crashes\n",
    "\n",
    "if not HAS_PYKRIGE:\n",
    "    print(\"‚ö† Skipping variogram analysis - PyKrige not installed\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VARIOGRAM ANALYSIS: ALL YEARS COMBINED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract coordinates and values\n",
    "    x_full = gdf_valid['x_utm'].values\n",
    "    y_full = gdf_valid['y_utm'].values\n",
    "    z_full = gdf_valid['relative_yield'].values\n",
    "    \n",
    "    # Subsample if dataset is very large (to avoid memory issues)\n",
    "    MAX_VARIOGRAM_POINTS = 50000  # Limit for variogram computation\n",
    "    \n",
    "    if len(z_full) > MAX_VARIOGRAM_POINTS:\n",
    "        logger.warning(f\"Dataset has {len(z_full):,} points - subsampling to {MAX_VARIOGRAM_POINTS:,} for variogram\")\n",
    "        logger.warning(f\"(Variogram doesn't need all points, random subsample is representative)\")\n",
    "        \n",
    "        # Random subsample\n",
    "        np.random.seed(42)\n",
    "        subsample_idx = np.random.choice(len(z_full), size=MAX_VARIOGRAM_POINTS, replace=False)\n",
    "        x = x_full[subsample_idx]\n",
    "        y = y_full[subsample_idx]\n",
    "        z = z_full[subsample_idx]\n",
    "        \n",
    "        print(f\"\\n‚ö† Using {len(z):,} / {len(z_full):,} points for variogram (random subsample)\")\n",
    "        print(f\"  This prevents memory issues while preserving spatial structure\")\n",
    "    else:\n",
    "        x = x_full\n",
    "        y = y_full\n",
    "        z = z_full\n",
    "    \n",
    "    logger.info(f\"Computing variogram for {len(z):,} points...\")\n",
    "    \n",
    "    # Test different variogram models\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    variogram_params = {}\n",
    "    \n",
    "    for idx, model in enumerate(VARIOGRAM_MODELS):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        try:\n",
    "            # Create kriging object to extract variogram\n",
    "            logger.info(f\"  Fitting {model} model...\")\n",
    "            ok = OrdinaryKriging(\n",
    "                x, y, z,\n",
    "                variogram_model=model,\n",
    "                nlags=N_LAGS,\n",
    "                enable_plotting=False,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Extract variogram parameters\n",
    "            variogram_params[model] = {\n",
    "                'sill': ok.variogram_model_parameters[0],\n",
    "                'range': ok.variogram_model_parameters[1],\n",
    "                'nugget': ok.variogram_model_parameters[2]\n",
    "            }\n",
    "            \n",
    "            # Plot experimental variogram\n",
    "            lags = ok.lags\n",
    "            semivariance = ok.semivariance\n",
    "            \n",
    "            ax.plot(lags, semivariance, 'o', label='Experimental', markersize=8, alpha=0.6)\n",
    "            \n",
    "            # Plot fitted model\n",
    "            lag_range = np.linspace(0, lags.max(), 100)\n",
    "            if model == 'spherical':\n",
    "                from pykrige.core import _variogram_spherical\n",
    "                model_values = _variogram_spherical(ok.variogram_model_parameters, lag_range)\n",
    "            elif model == 'exponential':\n",
    "                from pykrige.core import _variogram_exponential\n",
    "                model_values = _variogram_exponential(ok.variogram_model_parameters, lag_range)\n",
    "            elif model == 'gaussian':\n",
    "                from pykrige.core import _variogram_gaussian\n",
    "                model_values = _variogram_gaussian(ok.variogram_model_parameters, lag_range)\n",
    "            \n",
    "            ax.plot(lag_range, model_values, '-', label=f'Fitted {model.capitalize()}', linewidth=2)\n",
    "            \n",
    "            # Formatting\n",
    "            ax.set_xlabel('Distance (m)', fontsize=11)\n",
    "            ax.set_ylabel('Semivariance', fontsize=11)\n",
    "            ax.set_title(f'{model.capitalize()} Model\\nSill={variogram_params[model][\"sill\"]:.3f}, Range={variogram_params[model][\"range\"]:.0f}m',\n",
    "                        fontsize=12, fontweight='bold')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "        except MemoryError as e:\n",
    "            logger.error(f\"Memory error for {model} model - try reducing MAX_VARIOGRAM_POINTS\")\n",
    "            ax.text(0.5, 0.5, f'Memory Error\\n{model.capitalize()} model\\nReduce data size',\n",
    "                   ha='center', va='center', fontsize=12, color='red')\n",
    "            ax.set_xlabel('Distance (m)', fontsize=11)\n",
    "            ax.set_ylabel('Semivariance', fontsize=11)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fitting {model} model: {str(e)}\")\n",
    "            ax.text(0.5, 0.5, f'Error\\n{model.capitalize()} model\\n{str(e)[:50]}',\n",
    "                   ha='center', va='center', fontsize=10, color='red')\n",
    "            ax.set_xlabel('Distance (m)', fontsize=11)\n",
    "            ax.set_ylabel('Semivariance', fontsize=11)\n",
    "    \n",
    "    plt.suptitle(f'Variogram Models - All Years Combined (Relative Yield)\\nUsing {len(z):,} points', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(KRIGING_OUTPUT_DIR / 'variogram_combined.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    if variogram_params:\n",
    "        print(f\"\\nVariogram parameters:\")\n",
    "        for model, params in variogram_params.items():\n",
    "            print(f\"  {model.capitalize()}:\")\n",
    "            print(f\"    Sill: {params['sill']:.3f}\")\n",
    "            print(f\"    Range: {params['range']:.0f} m\")\n",
    "            print(f\"    Nugget: {params['nugget']:.3f}\")\n",
    "        \n",
    "        print(f\"\\nüí° Interpretation:\")\n",
    "        if 'spherical' in variogram_params:\n",
    "            print(f\"   - Range indicates the distance of spatial influence (~{variogram_params['spherical']['range']:.0f}m)\")\n",
    "        print(f\"   - Nugget shows measurement error + micro-scale variation\")\n",
    "        print(f\"   - Lower nugget = more reliable measurements\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå All variogram models failed - check memory and data quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bdbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variogram analysis: Separate by year\n",
    "\n",
    "if not HAS_PYKRIGE:\n",
    "    print(\"‚ö† Skipping variogram analysis - PyKrige not installed\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VARIOGRAM ANALYSIS: SEPARATE BY YEAR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    years = sorted(gdf_valid['Year'].unique())\n",
    "    n_years = len(years)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_years, figsize=(6*n_years, 5))\n",
    "    if n_years == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    variogram_params_yearly = {}\n",
    "    \n",
    "    for idx, year in enumerate(years):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Filter data for this year\n",
    "        year_data = gdf_valid[gdf_valid['Year'] == year]\n",
    "        \n",
    "        x = year_data['x_utm'].values\n",
    "        y = year_data['y_utm'].values\n",
    "        z = year_data['relative_yield'].values\n",
    "        \n",
    "        logger.info(f\"Computing variogram for {year}: {len(z)} points\")\n",
    "        \n",
    "        # Use spherical model (typically good for agricultural data)\n",
    "        ok = OrdinaryKriging(\n",
    "            x, y, z,\n",
    "            variogram_model='spherical',\n",
    "            nlags=N_LAGS,\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Store parameters\n",
    "        variogram_params_yearly[year] = {\n",
    "            'sill': ok.variogram_model_parameters[0],\n",
    "            'range': ok.variogram_model_parameters[1],\n",
    "            'nugget': ok.variogram_model_parameters[2]\n",
    "        }\n",
    "        \n",
    "        # Plot\n",
    "        lags = ok.lags\n",
    "        semivariance = ok.semivariance\n",
    "        \n",
    "        ax.plot(lags, semivariance, 'o', label='Experimental', markersize=8, alpha=0.6)\n",
    "        \n",
    "        # Fitted model\n",
    "        lag_range = np.linspace(0, lags.max(), 100)\n",
    "        from pykrige.core import _variogram_spherical\n",
    "        model_values = _variogram_spherical(ok.variogram_model_parameters, lag_range)\n",
    "        ax.plot(lag_range, model_values, '-', label='Fitted Spherical', linewidth=2)\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Distance (m)', fontsize=11)\n",
    "        ax.set_ylabel('Semivariance', fontsize=11)\n",
    "        ax.set_title(f'{year}\\n{len(z):,} points, Range={variogram_params_yearly[year][\"range\"]:.0f}m',\n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Variogram Models by Year (Spherical)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(KRIGING_OUTPUT_DIR / 'variogram_by_year.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nVariogram parameters by year:\")\n",
    "    for year, params in variogram_params_yearly.items():\n",
    "        print(f\"  {year}:\")\n",
    "        print(f\"    Sill: {params['sill']:.3f}\")\n",
    "        print(f\"    Range: {params['range']:.0f} m\")\n",
    "        print(f\"    Nugget: {params['nugget']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nüí° Compare ranges across years to see if spatial structure is consistent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17f0ff",
   "metadata": {},
   "source": [
    "## Section 5: Kriging Interpolation - Combined Model\n",
    "\n",
    "Perform kriging using all years combined. This assumes spatial patterns are similar across years (normalized by relative yield)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kriging: All years combined\n",
    "# Note: Kriging all 500k+ points can be slow - consider spatial thinning if needed\n",
    "\n",
    "if not HAS_PYKRIGE:\n",
    "    print(\"‚ö† Skipping kriging - PyKrige not installed\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KRIGING INTERPOLATION: ALL YEARS COMBINED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract data\n",
    "    x = gdf_valid['x_utm'].values\n",
    "    y = gdf_valid['y_utm'].values\n",
    "    z = gdf_valid['relative_yield'].values\n",
    "    \n",
    "    print(f\"Dataset: {len(z):,} points\")\n",
    "    \n",
    "    # Option: Spatial thinning for very large datasets\n",
    "    # Uncomment if kriging is too slow:\n",
    "    # MAX_KRIGING_POINTS = 100000\n",
    "    # if len(z) > MAX_KRIGING_POINTS:\n",
    "    #     print(f\"‚ö† Thinning to {MAX_KRIGING_POINTS:,} points for faster kriging\")\n",
    "    #     thin_idx = np.random.choice(len(z), size=MAX_KRIGING_POINTS, replace=False)\n",
    "    #     x, y, z = x[thin_idx], y[thin_idx], z[thin_idx]\n",
    "    \n",
    "    # Define grid extent\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    \n",
    "    # Create grid\n",
    "    grid_x = np.arange(x_min, x_max, GRID_RESOLUTION)\n",
    "    grid_y = np.arange(y_min, y_max, GRID_RESOLUTION)\n",
    "    \n",
    "    logger.info(f\"Grid size: {len(grid_x)} x {len(grid_y)} = {len(grid_x)*len(grid_y):,} cells\")\n",
    "    logger.info(f\"Performing ordinary kriging with spherical variogram...\")\n",
    "    logger.info(f\"‚ö† This may take several minutes with {len(z):,} points...\")\n",
    "    \n",
    "    try:\n",
    "        # Perform kriging\n",
    "        ok_combined = OrdinaryKriging(\n",
    "            x, y, z,\n",
    "            variogram_model='spherical',\n",
    "            nlags=N_LAGS,\n",
    "            enable_plotting=False,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Execute interpolation\n",
    "        print(f\"\\nExecuting kriging interpolation...\")\n",
    "        z_pred, ss_pred = ok_combined.execute('grid', grid_x, grid_y)\n",
    "        \n",
    "        logger.info(\"Kriging complete!\")\n",
    "        \n",
    "        # Plot results\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        \n",
    "        # Predicted values\n",
    "        ax = axes[0]\n",
    "        im1 = ax.imshow(\n",
    "            z_pred,\n",
    "            extent=[x_min, x_max, y_min, y_max],\n",
    "            origin='lower',\n",
    "            cmap='RdYlGn',\n",
    "            vmin=0.6,\n",
    "            vmax=1.4,\n",
    "            aspect='auto'\n",
    "        )\n",
    "        ax.scatter(x[::100], y[::100], c='black', s=1, alpha=0.2, label=f'Data points (every 100th)')\n",
    "        ax.set_xlabel('UTM X (m)', fontsize=11)\n",
    "        ax.set_ylabel('UTM Y (m)', fontsize=11)\n",
    "        ax.set_title(f'Kriging Prediction\\n(Relative Yield, {len(z):,} points)', fontsize=12, fontweight='bold')\n",
    "        cbar1 = plt.colorbar(im1, ax=ax)\n",
    "        cbar1.set_label('Relative Yield', fontsize=10)\n",
    "        ax.legend()\n",
    "        \n",
    "        # Prediction variance\n",
    "        ax = axes[1]\n",
    "        im2 = ax.imshow(\n",
    "            ss_pred,\n",
    "            extent=[x_min, x_max, y_min, y_max],\n",
    "            origin='lower',\n",
    "            cmap='viridis',\n",
    "            aspect='auto'\n",
    "        )\n",
    "        ax.scatter(x[::100], y[::100], c='white', s=1, alpha=0.3, label='Data points (every 100th)')\n",
    "        ax.set_xlabel('UTM X (m)', fontsize=11)\n",
    "        ax.set_ylabel('UTM Y (m)', fontsize=11)\n",
    "        ax.set_title('Kriging Variance\\n(Prediction Uncertainty)', fontsize=12, fontweight='bold')\n",
    "        cbar2 = plt.colorbar(im2, ax=ax)\n",
    "        cbar2.set_label('Variance', fontsize=10)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.suptitle('Kriging Results - All Years Combined', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(KRIGING_OUTPUT_DIR / 'kriging_combined.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n‚úì Kriging interpolation complete\")\n",
    "        print(f\"  Grid resolution: {GRID_RESOLUTION}m\")\n",
    "        print(f\"  Output grid: {len(grid_x)} x {len(grid_y)}\")\n",
    "        print(f\"  Mean predicted relative yield: {np.nanmean(z_pred):.3f}\")\n",
    "        print(f\"  Mean kriging variance: {np.nanmean(ss_pred):.3f}\")\n",
    "        \n",
    "        # Save results\n",
    "        kriging_combined_results = {\n",
    "            'z_pred': z_pred,\n",
    "            'ss_pred': ss_pred,\n",
    "            'grid_x': grid_x,\n",
    "            'grid_y': grid_y,\n",
    "            'ok_model': ok_combined\n",
    "        }\n",
    "        \n",
    "    except MemoryError as e:\n",
    "        print(f\"\\n‚ùå MEMORY ERROR: Dataset too large for kriging ({len(z):,} points)\")\n",
    "        print(f\"   Solutions:\")\n",
    "        print(f\"   1. Enable spatial thinning (uncomment code above)\")\n",
    "        print(f\"   2. Increase grid resolution (e.g., GRID_RESOLUTION = 20)\")\n",
    "        print(f\"   3. Use yearly kriging instead (fewer points per model)\")\n",
    "        print(f\"   4. Exclude more data in Section 3\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR during kriging: {str(e)}\")\n",
    "        print(f\"   Check error details above for diagnosis\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13fc1bd",
   "metadata": {},
   "source": [
    "## Section 6: Kriging Interpolation - Separate by Year\n",
    "\n",
    "Perform separate kriging for each year to capture year-specific spatial patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414453f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kriging: Separate models by year\n",
    "\n",
    "if not HAS_PYKRIGE:\n",
    "    print(\"‚ö† Skipping kriging - PyKrige not installed\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KRIGING INTERPOLATION: SEPARATE BY YEAR\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    years = sorted(gdf_valid['Year'].unique())\n",
    "    n_years = len(years)\n",
    "    \n",
    "    kriging_yearly_results = {}\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, n_years, figsize=(6*n_years, 12))\n",
    "    if n_years == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for idx, year in enumerate(years):\n",
    "        print(f\"\\nProcessing {year}...\")\n",
    "        \n",
    "        # Filter data\n",
    "        year_data = gdf_valid[gdf_valid['Year'] == year]\n",
    "        \n",
    "        x = year_data['x_utm'].values\n",
    "        y = year_data['y_utm'].values\n",
    "        z = year_data['relative_yield'].values\n",
    "        \n",
    "        # Define grid (same extent as combined)\n",
    "        x_min, x_max = gdf_valid['x_utm'].min(), gdf_valid['x_utm'].max()\n",
    "        y_min, y_max = gdf_valid['y_utm'].min(), gdf_valid['y_utm'].max()\n",
    "        \n",
    "        grid_x = np.arange(x_min, x_max, GRID_RESOLUTION)\n",
    "        grid_y = np.arange(y_min, y_max, GRID_RESOLUTION)\n",
    "        \n",
    "        logger.info(f\"  {year}: {len(z)} points ‚Üí {len(grid_x)}x{len(grid_y)} grid\")\n",
    "        \n",
    "        # Perform kriging\n",
    "        ok_year = OrdinaryKriging(\n",
    "            x, y, z,\n",
    "            variogram_model='spherical',\n",
    "            nlags=N_LAGS,\n",
    "            enable_plotting=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        z_pred, ss_pred = ok_year.execute('grid', grid_x, grid_y)\n",
    "        \n",
    "        # Store results\n",
    "        kriging_yearly_results[year] = {\n",
    "            'z_pred': z_pred,\n",
    "            'ss_pred': ss_pred,\n",
    "            'grid_x': grid_x,\n",
    "            'grid_y': grid_y,\n",
    "            'ok_model': ok_year\n",
    "        }\n",
    "        \n",
    "        # Plot prediction\n",
    "        ax = axes[0, idx]\n",
    "        im1 = ax.imshow(\n",
    "            z_pred,\n",
    "            extent=[x_min, x_max, y_min, y_max],\n",
    "            origin='lower',\n",
    "            cmap='RdYlGn',\n",
    "            vmin=0.6,\n",
    "            vmax=1.4,\n",
    "            aspect='auto'\n",
    "        )\n",
    "        ax.scatter(x, y, c='black', s=2, alpha=0.3)\n",
    "        ax.set_xlabel('UTM X (m)', fontsize=10)\n",
    "        ax.set_ylabel('UTM Y (m)', fontsize=10)\n",
    "        ax.set_title(f'{year} - Prediction\\n{len(z):,} points', fontsize=11, fontweight='bold')\n",
    "        plt.colorbar(im1, ax=ax, label='Relative Yield')\n",
    "        \n",
    "        # Plot variance\n",
    "        ax = axes[1, idx]\n",
    "        im2 = ax.imshow(\n",
    "            ss_pred,\n",
    "            extent=[x_min, x_max, y_min, y_max],\n",
    "            origin='lower',\n",
    "            cmap='viridis',\n",
    "            aspect='auto'\n",
    "        )\n",
    "        ax.scatter(x, y, c='white', s=2, alpha=0.3)\n",
    "        ax.set_xlabel('UTM X (m)', fontsize=10)\n",
    "        ax.set_ylabel('UTM Y (m)', fontsize=10)\n",
    "        ax.set_title(f'{year} - Variance', fontsize=11, fontweight='bold')\n",
    "        plt.colorbar(im2, ax=ax, label='Variance')\n",
    "        \n",
    "        print(f\"  ‚úì Mean prediction: {np.nanmean(z_pred):.3f}, Mean variance: {np.nanmean(ss_pred):.3f}\")\n",
    "    \n",
    "    plt.suptitle('Kriging Results by Year', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(KRIGING_OUTPUT_DIR / 'kriging_by_year.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úì Yearly kriging complete for {len(years)} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06c46c",
   "metadata": {},
   "source": [
    "## Section 7: Export Kriging Results\n",
    "\n",
    "Export the interpolated surfaces as GeoTIFF rasters for use in QGIS or other GIS software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488cf68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export kriging results to GeoTIFF\n",
    "\n",
    "if not HAS_RASTERIO:\n",
    "    print(\"‚ö† Rasterio not available - skipping GeoTIFF export\")\n",
    "    print(\"   Install with: pip install rasterio\")\n",
    "elif not HAS_PYKRIGE:\n",
    "    print(\"‚ö† Kriging not performed - no results to export\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPORTING KRIGING RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Export combined model\n",
    "    if 'kriging_combined_results' in locals():\n",
    "        z_pred = kriging_combined_results['z_pred']\n",
    "        grid_x = kriging_combined_results['grid_x']\n",
    "        grid_y = kriging_combined_results['grid_y']\n",
    "        \n",
    "        # Create transform\n",
    "        transform = from_bounds(\n",
    "            grid_x.min(), grid_y.min(),\n",
    "            grid_x.max(), grid_y.max(),\n",
    "            z_pred.shape[1], z_pred.shape[0]\n",
    "        )\n",
    "        \n",
    "        # Export prediction\n",
    "        output_path = KRIGING_OUTPUT_DIR / 'kriging_combined_prediction.tif'\n",
    "        with rasterio.open(\n",
    "            output_path, 'w',\n",
    "            driver='GTiff',\n",
    "            height=z_pred.shape[0],\n",
    "            width=z_pred.shape[1],\n",
    "            count=1,\n",
    "            dtype=z_pred.dtype,\n",
    "            crs='EPSG:25832',\n",
    "            transform=transform\n",
    "        ) as dst:\n",
    "            dst.write(z_pred, 1)\n",
    "        \n",
    "        logger.info(f\"Saved combined prediction: {output_path}\")\n",
    "        \n",
    "        # Export variance\n",
    "        ss_pred = kriging_combined_results['ss_pred']\n",
    "        output_path = KRIGING_OUTPUT_DIR / 'kriging_combined_variance.tif'\n",
    "        with rasterio.open(\n",
    "            output_path, 'w',\n",
    "            driver='GTiff',\n",
    "            height=ss_pred.shape[0],\n",
    "            width=ss_pred.shape[1],\n",
    "            count=1,\n",
    "            dtype=ss_pred.dtype,\n",
    "            crs='EPSG:25832',\n",
    "            transform=transform\n",
    "        ) as dst:\n",
    "            dst.write(ss_pred, 1)\n",
    "        \n",
    "        logger.info(f\"Saved combined variance: {output_path}\")\n",
    "    \n",
    "    # Export yearly models\n",
    "    if 'kriging_yearly_results' in locals():\n",
    "        for year, results in kriging_yearly_results.items():\n",
    "            z_pred = results['z_pred']\n",
    "            grid_x = results['grid_x']\n",
    "            grid_y = results['grid_y']\n",
    "            \n",
    "            transform = from_bounds(\n",
    "                grid_x.min(), grid_y.min(),\n",
    "                grid_x.max(), grid_y.max(),\n",
    "                z_pred.shape[1], z_pred.shape[0]\n",
    "            )\n",
    "            \n",
    "            # Export prediction\n",
    "            output_path = KRIGING_OUTPUT_DIR / f'kriging_{year}_prediction.tif'\n",
    "            with rasterio.open(\n",
    "                output_path, 'w',\n",
    "                driver='GTiff',\n",
    "                height=z_pred.shape[0],\n",
    "                width=z_pred.shape[1],\n",
    "                count=1,\n",
    "                dtype=z_pred.dtype,\n",
    "                crs='EPSG:25832',\n",
    "                transform=transform\n",
    "            ) as dst:\n",
    "                dst.write(z_pred, 1)\n",
    "            \n",
    "            logger.info(f\"Saved {year} prediction: {output_path}\")\n",
    "    \n",
    "    print(f\"\\n‚úì All kriging results exported to: {KRIGING_OUTPUT_DIR}\")\n",
    "    print(f\"\\nFiles created:\")\n",
    "    for f in sorted(KRIGING_OUTPUT_DIR.glob('*.tif')):\n",
    "        print(f\"  - {f.name}\")\n",
    "    \n",
    "    print(f\"\\nüí° Load these GeoTIFF files in QGIS to visualize the interpolated surfaces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6fe69",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### Results Summary\n",
    "\n",
    "This notebook performed kriging interpolation with two approaches:\n",
    "\n",
    "1. **Combined Model (All Years)**: Uses all data points together, leveraging normalized relative yield\n",
    "2. **Yearly Models**: Separate kriging for each year to capture temporal variations\n",
    "\n",
    "### Outputs Created\n",
    "\n",
    "- Variogram plots showing spatial correlation structure\n",
    "- Interpolated yield surfaces (GeoTIFF rasters)\n",
    "- Kriging variance maps (prediction uncertainty)\n",
    "- Comparison visualizations\n",
    "\n",
    "### Interpretation Tips\n",
    "\n",
    "- **High variance areas**: Less data coverage, less reliable predictions\n",
    "- **Range parameter**: Typical distance of spatial correlation\n",
    "- **Nugget effect**: Measurement error + micro-scale variation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Visual inspection**: Load GeoTIFF files in QGIS to compare approaches\n",
    "2. **Validation**: Use cross-validation to assess prediction accuracy\n",
    "3. **Comparison**: Decide which approach (combined vs yearly) works better for your data\n",
    "4. **Management zones**: Use interpolated surfaces to delineate high/low yield zones\n",
    "5. **Temporal analysis**: Compare yearly surfaces to identify persistent patterns\n",
    "\n",
    "### Manual Exclusion\n",
    "\n",
    "If you identified problematic areas (e.g., harvester edge effects), go back to Section 3 and add exclusion criteria based on:\n",
    "- Field names\n",
    "- Coordinate ranges\n",
    "- Relative yield thresholds\n",
    "- Visual inspection of maps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyagri-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
